name: Deploy Context SSG to R2 (Distributed)

# ì²­í¬ ê¸°ë°˜ ë¶„ì‚° ë¹Œë“œ â†’ R2 ë°°í¬
# - 100ë§Œ+ ì—”íŠ¸ë¦¬ ëŒ€ì‘ ê°€ëŠ¥
# - Matrixë¡œ ë³‘ë ¬ ë¹Œë“œ í›„ ë³‘í•©
#
# íŠ¸ë¦¬ê±°:
# - data/context/** ë³€ê²½ ì‹œ ìë™ ì‹¤í–‰
# - workflow_dispatchë¡œ ìˆ˜ë™ ì‹¤í–‰ (dry_run ì˜µì…˜)

on:
  push:
    branches: [main]
    paths:
      - 'data/context/**'
      - 'apps/context/**'
      - 'packages/**'
  workflow_dispatch:
    inputs:
      chunk_size:
        description: 'ì²­í¬ë‹¹ ì—”íŠ¸ë¦¬ ìˆ˜ (ê¸°ë³¸: 50000)'
        required: false
        default: '50000'
      dry_run:
        description: 'Dry run (R2 ì—…ë¡œë“œ ìŠ¤í‚µ)'
        required: false
        default: 'false'
        type: boolean

concurrency:
  group: deploy-context-r2-${{ github.ref }}
  cancel-in-progress: true

env:
  CHUNK_SIZE: ${{ github.event.inputs.chunk_size || '50000' }}

jobs:
  # ============================================================================
  # 1ë‹¨ê³„: ì²­í¬ ìˆ˜ ê³„ì‚° ë° prebuild
  # ============================================================================
  prepare:
    name: Prepare & Calculate Chunks
    runs-on: ubuntu-latest
    outputs:
      chunk_indices: ${{ steps.calc.outputs.chunk_indices }}
      total_chunks: ${{ steps.calc.outputs.total_chunks }}
      total_entries: ${{ steps.calc.outputs.total_entries }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Run prebuild (generate entries data)
        run: pnpm prebuild
        working-directory: apps/context

      - name: Calculate chunk count
        id: calc
        working-directory: apps/context
        run: |
          # ì²­í¬ ë©”íƒ€ë°ì´í„° ê³„ì‚°
          RESULT=$(npx tsx -e "
            import('./app/data/route-chunks.js').then(async (m) => {
              const meta = await m.getChunkMetadata(parseInt(process.env.CHUNK_SIZE || '50000'));
              console.log(JSON.stringify(meta));
            });
          ")

          TOTAL_ENTRIES=$(echo $RESULT | jq -r '.totalEntries')
          TOTAL_CHUNKS=$(echo $RESULT | jq -r '.totalChunks')

          # ì²­í¬ ì¸ë±ìŠ¤ ë°°ì—´ ìƒì„± [0, 1, 2, ...]
          CHUNK_INDICES=$(seq 0 $((TOTAL_CHUNKS - 1)) | jq -R -s -c 'split("\n")[:-1] | map(tonumber)')

          echo "total_entries=$TOTAL_ENTRIES" >> $GITHUB_OUTPUT
          echo "total_chunks=$TOTAL_CHUNKS" >> $GITHUB_OUTPUT
          echo "chunk_indices=$CHUNK_INDICES" >> $GITHUB_OUTPUT

          echo "ğŸ“Š Total entries: $TOTAL_ENTRIES"
          echo "ğŸ“Š Total chunks: $TOTAL_CHUNKS (chunk size: $CHUNK_SIZE)"
          echo "ğŸ“Š Chunk indices: $CHUNK_INDICES"

      - name: Upload prebuild artifacts
        uses: actions/upload-artifact@v4
        with:
          name: prebuild-data
          path: |
            apps/context/app/data/generated/
            apps/context/public/data/
          retention-days: 1

  # ============================================================================
  # 2ë‹¨ê³„: ì²­í¬ë³„ ë³‘ë ¬ ë¹Œë“œ
  # ============================================================================
  build-chunk:
    name: Build Chunk ${{ matrix.chunk }}
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: ${{ fromJson(needs.prepare.outputs.chunk_indices) }}
      max-parallel: 20  # GitHub Actions ë™ì‹œ ì‹¤í–‰ ì œí•œ
      fail-fast: false  # í•˜ë‚˜ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ ê³„ì† ì§„í–‰
    steps:
      - uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Download prebuild artifacts
        uses: actions/download-artifact@v4
        with:
          name: prebuild-data
          path: apps/context/

      - name: Build chunk ${{ matrix.chunk }}
        working-directory: apps/context
        run: |
          echo "ğŸ”¨ Building chunk ${{ matrix.chunk }} of ${{ needs.prepare.outputs.total_chunks }}"
          npx react-router build
        env:
          BUILD_TARGET: chunked
          CHUNK_INDEX: ${{ matrix.chunk }}
          CHUNK_SIZE: ${{ env.CHUNK_SIZE }}
          NODE_OPTIONS: '--max-old-space-size=4096'

      - name: Upload chunk build
        uses: actions/upload-artifact@v4
        with:
          name: build-chunk-${{ matrix.chunk }}
          path: |
            apps/context/build/client/entry/
            apps/context/build/client/ko/entry/
          retention-days: 1
          if-no-files-found: warn

  # ============================================================================
  # 3ë‹¨ê³„: ë¹Œë“œ ê²°ê³¼ ë³‘í•© ë° R2 ë°°í¬
  # ============================================================================
  deploy:
    name: Merge & Deploy to R2
    needs: [prepare, build-chunk]
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.dry_run != 'true' }}
    steps:
      - uses: actions/checkout@v4

      - name: Download all chunk builds
        uses: actions/download-artifact@v4
        with:
          path: merged-builds/
          pattern: build-chunk-*
          merge-multiple: true

      - name: Verify merged builds
        run: |
          echo "ğŸ“Š Merged build statistics:"
          echo "   English entries: $(find merged-builds/entry -name '*.html' 2>/dev/null | wc -l)"
          echo "   Korean entries: $(find merged-builds/ko/entry -name '*.html' 2>/dev/null | wc -l)"

          EXPECTED=$(( ${{ needs.prepare.outputs.total_entries }} * 2 ))
          ACTUAL=$(find merged-builds -name '*.html' | wc -l)

          echo "   Expected: $EXPECTED HTML files"
          echo "   Actual: $ACTUAL HTML files"

          if [ "$ACTUAL" -lt "$EXPECTED" ]; then
            echo "âš ï¸ Warning: Some HTML files may be missing"
          fi

      - name: Verify SSG HTML content (404 detection)
        run: |
          echo "ğŸ” ë¹Œë“œëœ HTMLì—ì„œ 404 ì½˜í…ì¸  ê°ì§€ ê²€ì‚¬ ì¤‘..."

          # 404 íŒ¨í„´ ëª©ë¡
          NOT_FOUND_PATTERNS=(
            "ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            "Entry Not Found"
            "í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            "Page Not Found"
          )

          FAILED=0

          # ì˜ì–´ entry í˜ì´ì§€ ê²€ì‚¬
          echo "ğŸ“‚ ì˜ì–´ entry í˜ì´ì§€ ê²€ì‚¬..."
          for pattern in "${NOT_FOUND_PATTERNS[@]}"; do
            COUNT=$(grep -r "<title[^>]*>$pattern" merged-builds/entry/ 2>/dev/null | wc -l || echo "0")
            if [ "$COUNT" -gt 0 ]; then
              echo "âŒ ì˜ì–´ entry í˜ì´ì§€ì—ì„œ '$pattern' íŒ¨í„´ $COUNTê°œ ë°œê²¬"
              FAILED=$((FAILED + COUNT))
            fi
          done

          # í•œê¸€ entry í˜ì´ì§€ ê²€ì‚¬
          echo "ğŸ“‚ í•œê¸€ entry í˜ì´ì§€ ê²€ì‚¬..."
          for pattern in "${NOT_FOUND_PATTERNS[@]}"; do
            COUNT=$(grep -r "<title[^>]*>$pattern" merged-builds/ko/entry/ 2>/dev/null | wc -l || echo "0")
            if [ "$COUNT" -gt 0 ]; then
              echo "âŒ í•œê¸€ entry í˜ì´ì§€ì—ì„œ '$pattern' íŒ¨í„´ $COUNTê°œ ë°œê²¬"
              FAILED=$((FAILED + COUNT))
            fi
          done

          if [ "$FAILED" -gt 0 ]; then
            echo ""
            echo "âŒ ì´ $FAILEDê°œì˜ 404 ì½˜í…ì¸  ê°ì§€ë¨!"
            echo "   loaderì—ì„œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ - params.locale ì‚¬ìš© ì—¬ë¶€ í™•ì¸ í•„ìš”"
            exit 1
          fi

          echo "âœ… ëª¨ë“  entry í˜ì´ì§€ ì½˜í…ì¸  ì •ìƒ (404 ì—†ìŒ)"

      - name: Install rclone
        run: curl -fsSL https://rclone.org/install.sh | sudo bash

      - name: Configure rclone for R2
        run: |
          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << EOF
          [r2]
          type = s3
          provider = Cloudflare
          access_key_id = ${{ secrets.R2_ACCESS_KEY_ID }}
          secret_access_key = ${{ secrets.R2_SECRET_ACCESS_KEY }}
          endpoint = https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com
          acl = private
          EOF

      - name: Sync to R2
        run: |
          echo "ğŸ“¤ Uploading English entries..."
          rclone sync merged-builds/entry r2:all-sites-static/public-monorepo/context/entry \
            --checksum --transfers 32 --checkers 32 --fast-list \
            --stats 10s --stats-one-line -v

          echo "ğŸ“¤ Uploading Korean entries..."
          rclone sync merged-builds/ko/entry r2:all-sites-static/public-monorepo/context/ko/entry \
            --checksum --transfers 32 --checkers 32 --fast-list \
            --stats 10s --stats-one-line -v

      - name: Wait for CDN propagation
        run: sleep 30

      - name: Verify SSG URLs (sample test)
        run: |
          echo "ğŸ” ì‚¬ì´íŠ¸ë§µ URL ìƒ˜í”Œ ê²€ì¦ ì¤‘..."

          # ì‚¬ì´íŠ¸ë§µ ì¸ë±ìŠ¤ì—ì„œ entry ì‚¬ì´íŠ¸ë§µ ëª©ë¡ ì¶”ì¶œ
          ENTRY_SITEMAPS=$(curl -s https://context.soundbluemusic.com/sitemap.xml | \
            grep -oP '(?<=<loc>)[^<]+sitemap-entry-[^<]+')

          # ê° ì¹´í…Œê³ ë¦¬ ì‚¬ì´íŠ¸ë§µì—ì„œ URL ìƒ˜í”Œ ì¶”ì¶œ (ì´ 100ê°œ)
          > /tmp/sample-urls.txt
          for sitemap in $ENTRY_SITEMAPS; do
            curl -s "$sitemap" | grep -oP '(?<=<loc>)[^<]+' | shuf -n 4 >> /tmp/sample-urls.txt
          done
          shuf -n 100 /tmp/sample-urls.txt > /tmp/sample-urls-final.txt
          mv /tmp/sample-urls-final.txt /tmp/sample-urls.txt

          FAILED=0
          TESTED=0

          while IFS= read -r url; do
            TESTED=$((TESTED + 1))
            STATUS=$(curl -s -o /dev/null -w "%{http_code}" -H "Cache-Control: no-cache" "$url")
            SSG_SOURCE=$(curl -s -I -H "Cache-Control: no-cache" "$url" | grep -i "x-ssg-source" | cut -d: -f2 | tr -d ' \r')

            if [ "$STATUS" != "200" ]; then
              echo "âŒ [$STATUS] $url"
              FAILED=$((FAILED + 1))
            elif [ "$SSG_SOURCE" != "r2" ]; then
              echo "âš ï¸ [SPA fallback] $url (X-SSG-Source: $SSG_SOURCE)"
              FAILED=$((FAILED + 1))
            fi
          done < /tmp/sample-urls.txt

          echo ""
          echo "ğŸ“Š ê²€ì¦ ê²°ê³¼: $TESTEDê°œ í…ŒìŠ¤íŠ¸, $FAILEDê°œ ì‹¤íŒ¨"

          if [ "$FAILED" -gt 0 ]; then
            echo "âŒ R2 SSG ì„œë¹™ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤!"
            exit 1
          fi

          echo "âœ… ëª¨ë“  ìƒ˜í”Œ URLì´ R2ì—ì„œ ì •ìƒ ì„œë¹™ë©ë‹ˆë‹¤."

      - name: Summary
        run: |
          echo "âœ… R2 SSG ë°°í¬ ì™„ë£Œ (ë¶„ì‚° ë¹Œë“œ)"
          echo "   - ì´ ì—”íŠ¸ë¦¬: ${{ needs.prepare.outputs.total_entries }}"
          echo "   - ì´ ì²­í¬: ${{ needs.prepare.outputs.total_chunks }}"
          echo "   - ì²­í¬ í¬ê¸°: ${{ env.CHUNK_SIZE }}"
          echo "   - ì˜ì–´ ì—”íŠ¸ë¦¬: /entry/*"
          echo "   - í•œêµ­ì–´ ì—”íŠ¸ë¦¬: /ko/entry/*"
          echo "   - ìƒ˜í”Œ ê²€ì¦: 100ê°œ URL í†µê³¼"

  # ============================================================================
  # Dry run ìš”ì•½ (R2 ì—…ë¡œë“œ ìŠ¤í‚µ ì‹œ)
  # ============================================================================
  dry-run-summary:
    name: Dry Run Summary
    needs: [prepare, build-chunk]
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.dry_run == 'true' }}
    steps:
      - name: Download all chunk builds
        uses: actions/download-artifact@v4
        with:
          path: merged-builds/
          pattern: build-chunk-*
          merge-multiple: true

      - name: Summary
        run: |
          echo "ğŸ§ª Dry run complete (R2 upload skipped)"
          echo ""
          echo "ğŸ“Š Build statistics:"
          echo "   Total entries: ${{ needs.prepare.outputs.total_entries }}"
          echo "   Total chunks: ${{ needs.prepare.outputs.total_chunks }}"
          echo "   Chunk size: ${{ env.CHUNK_SIZE }}"
          echo ""
          echo "   English entries built: $(find merged-builds/entry -name '*.html' 2>/dev/null | wc -l)"
          echo "   Korean entries built: $(find merged-builds/ko/entry -name '*.html' 2>/dev/null | wc -l)"
