{"code":"const optimizationConcepts=[{id:\"optimization-basics\",name:{ko:\"\\uCD5C\\uC801\\uD654 \\uAE30\\uCD08\",en:\"Optimization Basics\"},field:\"optimization\",subfield:\"foundations\",difficulty:3,content:{ko:{definition:\"\\uCD5C\\uC801\\uD654\\uB294 \\uC8FC\\uC5B4\\uC9C4 \\uC870\\uAC74 \\uD558\\uC5D0\\uC11C \\uBAA9\\uC801\\uD568\\uC218\\uB97C \\uCD5C\\uB300\\uD654\\uD558\\uAC70\\uB098 \\uCD5C\\uC18C\\uD654\\uD558\\uB294 \\uBCC0\\uC218 \\uAC12\\uC744 \\uCC3E\\uB294 \\uAC83\\uC785\\uB2C8\\uB2E4.\",formulas:[{latex:\"\\\\min_{x} f(x) \\\\quad \\\\text{subject to} \\\\quad g(x) \\\\leq 0, h(x) = 0\",description:\"\\uC77C\\uBC18\\uC801\\uC778 \\uCD5C\\uC801\\uD654 \\uBB38\\uC81C\"},{latex:\"\\\\nabla f(x^*) = 0\",description:\"\\uBB34\\uC81C\\uC57D \\uCD5C\\uC801\\uD654\\uC758 \\uD544\\uC694\\uC870\\uAC74\"}],examples:[{problem:\"f(x) = x\\xB2 - 4x + 5\\uC758 \\uCD5C\\uC19F\\uAC12\\uC744 \\uAD6C\\uD558\\uC138\\uC694.\",solution:\"f'(x) = 2x - 4 = 0\\uC5D0\\uC11C x = 2. f''(2) = 2 > 0\\uC774\\uBBC0\\uB85C \\uCD5C\\uC19F\\uAC12. f(2) = 4 - 8 + 5 = 1\"}],applications:[{field:\"\\uAE30\\uACC4\\uD559\\uC2B5\",description:\"\\uC190\\uC2E4\\uD568\\uC218 \\uCD5C\\uC18C\\uD654\"},{field:\"\\uACBD\\uC81C\\uD559\",description:\"\\uD6A8\\uC6A9 \\uCD5C\\uB300\\uD654\"},{field:\"\\uACF5\\uD559\",description:\"\\uC124\\uACC4 \\uCD5C\\uC801\\uD654\"}]},en:{definition:\"Optimization is finding variable values that maximize or minimize an objective function under given constraints.\",formulas:[{latex:\"\\\\min_{x} f(x) \\\\quad \\\\text{subject to} \\\\quad g(x) \\\\leq 0, h(x) = 0\",description:\"General optimization problem\"},{latex:\"\\\\nabla f(x^*) = 0\",description:\"Necessary condition for unconstrained optimization\"}],examples:[{problem:\"Find the minimum of f(x) = x\\xB2 - 4x + 5.\",solution:\"f'(x) = 2x - 4 = 0 gives x = 2. f''(2) = 2 > 0, so minimum. f(2) = 4 - 8 + 5 = 1\"}],applications:[{field:\"Machine Learning\",description:\"Loss function minimization\"},{field:\"Economics\",description:\"Utility maximization\"},{field:\"Engineering\",description:\"Design optimization\"}]}},relations:{prerequisites:[\"derivative\",\"gradient\"],nextTopics:[\"gradient-descent\",\"lagrange-multipliers\"],related:[\"calculus\"]},tags:[\"\\uCD5C\\uC801\\uD654\",\"\\uCD5C\\uC19F\\uAC12\",\"optimization\",\"minimum\"]},{id:\"gradient-descent\",name:{ko:\"\\uACBD\\uC0AC \\uD558\\uAC15\\uBC95\",en:\"Gradient Descent\"},field:\"optimization\",subfield:\"algorithms\",difficulty:3,content:{ko:{definition:\"\\uACBD\\uC0AC \\uD558\\uAC15\\uBC95\\uC740 \\uD568\\uC218\\uC758 \\uADF8\\uB798\\uB514\\uC5B8\\uD2B8(\\uAE30\\uC6B8\\uAE30) \\uBC18\\uB300 \\uBC29\\uD5A5\\uC73C\\uB85C \\uBC18\\uBCF5\\uC801\\uC73C\\uB85C \\uC774\\uB3D9\\uD558\\uC5EC \\uCD5C\\uC19F\\uAC12\\uC744 \\uCC3E\\uB294 \\uCD5C\\uC801\\uD654 \\uC54C\\uACE0\\uB9AC\\uC998\\uC785\\uB2C8\\uB2E4.\",formulas:[{latex:\"x_{n+1} = x_n - \\\\alpha \\\\nabla f(x_n)\",description:\"\\uACBD\\uC0AC \\uD558\\uAC15\\uBC95 \\uC5C5\\uB370\\uC774\\uD2B8 \\uADDC\\uCE59\"},{latex:\"\\\\alpha\",description:\"\\uD559\\uC2B5\\uB960 (step size)\"}],examples:[{problem:\"f(x) = x\\xB2\\uC5D0 \\uACBD\\uC0AC \\uD558\\uAC15\\uBC95\\uC744 x\\u2080 = 4, \\u03B1 = 0.5\\uB85C \\uC801\\uC6A9\\uD558\\uC138\\uC694.\",solution:\"f'(x) = 2x. x\\u2081 = 4 - 0.5(8) = 0. \\uD55C \\uBC88\\uC758 \\uBC18\\uBCF5\\uC73C\\uB85C \\uCD5C\\uC19F\\uAC12\\uC5D0 \\uB3C4\\uB2EC.\"}],applications:[{field:\"\\uB525\\uB7EC\\uB2DD\",description:\"\\uC2E0\\uACBD\\uB9DD \\uD559\\uC2B5\"},{field:\"\\uAE30\\uACC4\\uD559\\uC2B5\",description:\"\\uBAA8\\uB378 \\uD30C\\uB77C\\uBBF8\\uD130 \\uCD5C\\uC801\\uD654\"},{field:\"\\uB370\\uC774\\uD130 \\uACFC\\uD559\",description:\"\\uD68C\\uADC0 \\uBD84\\uC11D\"}]},en:{definition:\"Gradient descent is an optimization algorithm that iteratively moves in the opposite direction of the gradient to find the minimum.\",formulas:[{latex:\"x_{n+1} = x_n - \\\\alpha \\\\nabla f(x_n)\",description:\"Gradient descent update rule\"},{latex:\"\\\\alpha\",description:\"Learning rate (step size)\"}],examples:[{problem:\"Apply gradient descent to f(x) = x\\xB2 with x\\u2080 = 4, \\u03B1 = 0.5.\",solution:\"f'(x) = 2x. x\\u2081 = 4 - 0.5(8) = 0. Reaches minimum in one iteration.\"}],applications:[{field:\"Deep Learning\",description:\"Neural network training\"},{field:\"Machine Learning\",description:\"Model parameter optimization\"},{field:\"Data Science\",description:\"Regression analysis\"}]}},relations:{prerequisites:[\"gradient\",\"derivative\"],nextTopics:[\"stochastic-gd\",\"adam-optimizer\"],related:[\"backpropagation\"]},tags:[\"\\uACBD\\uC0AC\\uD558\\uAC15\",\"\\uAE30\\uC6B8\\uAE30\",\"gradient descent\",\"optimization\"]},{id:\"lagrange-multipliers\",name:{ko:\"\\uB77C\\uADF8\\uB791\\uC8FC \\uC2B9\\uC218\\uBC95\",en:\"Lagrange Multipliers\"},field:\"optimization\",subfield:\"constrained\",difficulty:4,content:{ko:{definition:\"\\uB77C\\uADF8\\uB791\\uC8FC \\uC2B9\\uC218\\uBC95\\uC740 \\uB4F1\\uC2DD \\uC81C\\uC57D \\uC870\\uAC74\\uC774 \\uC788\\uB294 \\uCD5C\\uC801\\uD654 \\uBB38\\uC81C\\uB97C \\uD478\\uB294 \\uBC29\\uBC95\\uC785\\uB2C8\\uB2E4. \\uC81C\\uC57D \\uC870\\uAC74\\uC744 \\uC0C8\\uB85C\\uC6B4 \\uBCC0\\uC218(\\uC2B9\\uC218)\\uC640 \\uACB0\\uD569\\uD569\\uB2C8\\uB2E4.\",formulas:[{latex:\"\\\\mathcal{L}(x, \\\\lambda) = f(x) - \\\\lambda g(x)\",description:\"\\uB77C\\uADF8\\uB791\\uC9C0\\uC548\"},{latex:\"\\\\nabla f = \\\\lambda \\\\nabla g\",description:\"\\uCD5C\\uC801\\uC810\\uC5D0\\uC11C\\uC758 \\uC870\\uAC74\"}],examples:[{problem:\"x + y = 10 \\uC81C\\uC57D \\uD558\\uC5D0\\uC11C xy\\uB97C \\uCD5C\\uB300\\uD654\\uD558\\uC138\\uC694.\",solution:\"L = xy - \\u03BB(x+y-10). \\u2202L/\\u2202x = y - \\u03BB = 0, \\u2202L/\\u2202y = x - \\u03BB = 0. x = y\\uC774\\uACE0 x + y = 10\\uC774\\uBBC0\\uB85C x = y = 5. \\uCD5C\\uB313\\uAC12 = 25\"}],history:{discoveredBy:\"\\uC870\\uC81C\\uD504\\uB8E8\\uC774 \\uB77C\\uADF8\\uB791\\uC8FC\",year:\"1788\\uB144\",background:\"\\uB77C\\uADF8\\uB791\\uC8FC\\uAC00 \\uC5ED\\uD559 \\uBB38\\uC81C\\uB97C \\uD480\\uBA74\\uC11C \\uC774 \\uBC29\\uBC95\\uC744 \\uAC1C\\uBC1C\\uD588\\uC2B5\\uB2C8\\uB2E4.\"},applications:[{field:\"\\uACBD\\uC81C\\uD559\",description:\"\\uC608\\uC0B0 \\uC81C\\uC57D \\uD558 \\uD6A8\\uC6A9 \\uCD5C\\uB300\\uD654\"},{field:\"\\uBB3C\\uB9AC\\uD559\",description:\"\\uC5ED\\uD559\\uC801 \\uC81C\\uC57D \\uC870\\uAC74\"},{field:\"\\uAE30\\uACC4\\uD559\\uC2B5\",description:\"SVM\\uC758 \\uCD5C\\uC801\\uD654\"}]},en:{definition:\"Lagrange multipliers method solves optimization problems with equality constraints by combining constraints with new variables (multipliers).\",formulas:[{latex:\"\\\\mathcal{L}(x, \\\\lambda) = f(x) - \\\\lambda g(x)\",description:\"Lagrangian\"},{latex:\"\\\\nabla f = \\\\lambda \\\\nabla g\",description:\"Condition at optimum\"}],examples:[{problem:\"Maximize xy subject to x + y = 10.\",solution:\"L = xy - \\u03BB(x+y-10). \\u2202L/\\u2202x = y - \\u03BB = 0, \\u2202L/\\u2202y = x - \\u03BB = 0. x = y and x + y = 10, so x = y = 5. Maximum = 25\"}],history:{discoveredBy:\"Joseph-Louis Lagrange\",year:\"1788\",background:\"Lagrange developed this method while solving mechanics problems.\"},applications:[{field:\"Economics\",description:\"Utility maximization under budget\"},{field:\"Physics\",description:\"Mechanical constraints\"},{field:\"Machine Learning\",description:\"SVM optimization\"}]}},relations:{prerequisites:[\"gradient\",\"optimization-basics\"],nextTopics:[\"kkt-conditions\",\"convex-optimization\"],related:[\"multivariable-calculus\"]},tags:[\"\\uB77C\\uADF8\\uB791\\uC8FC\",\"\\uC81C\\uC57D\",\"Lagrange\",\"constraint\"]},{id:\"linear-programming\",name:{ko:\"\\uC120\\uD615 \\uACC4\\uD68D\\uBC95\",en:\"Linear Programming\"},field:\"optimization\",subfield:\"linear\",difficulty:3,content:{ko:{definition:\"\\uC120\\uD615 \\uACC4\\uD68D\\uBC95\\uC740 \\uC120\\uD615 \\uBAA9\\uC801\\uD568\\uC218\\uB97C \\uC120\\uD615 \\uC81C\\uC57D\\uC870\\uAC74 \\uD558\\uC5D0\\uC11C \\uCD5C\\uC801\\uD654\\uD558\\uB294 \\uBC29\\uBC95\\uC785\\uB2C8\\uB2E4. \\uC2EC\\uD50C\\uB809\\uC2A4 \\uC54C\\uACE0\\uB9AC\\uC998\\uC73C\\uB85C \\uD6A8\\uC728\\uC801\\uC73C\\uB85C \\uD480 \\uC218 \\uC788\\uC2B5\\uB2C8\\uB2E4.\",formulas:[{latex:\"\\\\max c^T x \\\\quad \\\\text{s.t.} \\\\quad Ax \\\\leq b, x \\\\geq 0\",description:\"\\uD45C\\uC900\\uD615 \\uC120\\uD615 \\uACC4\\uD68D \\uBB38\\uC81C\"}],examples:[{problem:\"max 3x + 2y, s.t. x + y \\u2264 4, 2x + y \\u2264 6, x,y \\u2265 0\\uC744 \\uD478\\uC138\\uC694.\",solution:\"\\uAF2D\\uC9D3\\uC810 \\uAC80\\uC0AC: (0,0)\\u21920, (0,4)\\u21928, (2,2)\\u219210, (3,0)\\u21929. \\uCD5C\\uC801\\uD574: (2,2), \\uCD5C\\uB313\\uAC12: 10\"}],history:{discoveredBy:\"\\uC870\\uC9C0 \\uB2E8\\uCE58\\uADF8\",year:\"1947\\uB144\",background:\"\\uB2E8\\uCE58\\uADF8\\uAC00 \\uC2EC\\uD50C\\uB809\\uC2A4 \\uC54C\\uACE0\\uB9AC\\uC998\\uC744 \\uAC1C\\uBC1C\\uD558\\uC5EC \\uC120\\uD615 \\uACC4\\uD68D\\uBC95\\uC744 \\uC2E4\\uC6A9\\uC801\\uC73C\\uB85C \\uB9CC\\uB4E4\\uC5C8\\uC2B5\\uB2C8\\uB2E4.\"},applications:[{field:\"\\uC6B4\\uC601 \\uC5F0\\uAD6C\",description:\"\\uC790\\uC6D0 \\uBC30\\uBD84, \\uC2A4\\uCF00\\uC904\\uB9C1\"},{field:\"\\uBB3C\\uB958\",description:\"\\uC6B4\\uC1A1 \\uCD5C\\uC801\\uD654\"},{field:\"\\uAE08\\uC735\",description:\"\\uD3EC\\uD2B8\\uD3F4\\uB9AC\\uC624 \\uCD5C\\uC801\\uD654\"}]},en:{definition:\"Linear programming optimizes a linear objective function under linear constraints. The simplex algorithm solves it efficiently.\",formulas:[{latex:\"\\\\max c^T x \\\\quad \\\\text{s.t.} \\\\quad Ax \\\\leq b, x \\\\geq 0\",description:\"Standard form linear program\"}],examples:[{problem:\"Solve max 3x + 2y, s.t. x + y \\u2264 4, 2x + y \\u2264 6, x,y \\u2265 0.\",solution:\"Check vertices: (0,0)\\u21920, (0,4)\\u21928, (2,2)\\u219210, (3,0)\\u21929. Optimal: (2,2), max: 10\"}],history:{discoveredBy:\"George Dantzig\",year:\"1947\",background:\"Dantzig developed the simplex algorithm, making linear programming practical.\"},applications:[{field:\"Operations Research\",description:\"Resource allocation, scheduling\"},{field:\"Logistics\",description:\"Transportation optimization\"},{field:\"Finance\",description:\"Portfolio optimization\"}]}},relations:{prerequisites:[\"linear-algebra\",\"inequalities\"],nextTopics:[\"integer-programming\",\"duality\"],related:[\"simplex-algorithm\"]},tags:[\"\\uC120\\uD615\\uACC4\\uD68D\",\"\\uC2EC\\uD50C\\uB809\\uC2A4\",\"linear programming\",\"LP\"]},{id:\"convex-optimization\",name:{ko:\"\\uBCFC\\uB85D \\uCD5C\\uC801\\uD654\",en:\"Convex Optimization\"},field:\"optimization\",subfield:\"convex\",difficulty:4,content:{ko:{definition:\"\\uBCFC\\uB85D \\uCD5C\\uC801\\uD654\\uB294 \\uBCFC\\uB85D \\uC9D1\\uD569\\uC5D0\\uC11C \\uBCFC\\uB85D \\uD568\\uC218\\uB97C \\uCD5C\\uC18C\\uD654\\uD558\\uB294 \\uBB38\\uC81C\\uC785\\uB2C8\\uB2E4. \\uC9C0\\uC5ED \\uCD5C\\uC19F\\uAC12\\uC774 \\uC804\\uC5ED \\uCD5C\\uC19F\\uAC12\\uC774 \\uB418\\uC5B4 \\uD6A8\\uC728\\uC801\\uC73C\\uB85C \\uD480 \\uC218 \\uC788\\uC2B5\\uB2C8\\uB2E4.\",formulas:[{latex:\"f(\\\\theta x + (1-\\\\theta)y) \\\\leq \\\\theta f(x) + (1-\\\\theta)f(y)\",description:\"\\uBCFC\\uB85D \\uD568\\uC218\\uC758 \\uC815\\uC758\"},{latex:\"\\\\nabla^2 f(x) \\\\succeq 0\",description:\"\\uBCFC\\uB85D\\uC131\\uC758 \\uC774\\uACC4 \\uC870\\uAC74 (\\uD5E4\\uC2DC\\uC548\\uC774 \\uC591\\uBC18\\uC815\\uCE58)\"}],examples:[{problem:\"f(x) = x\\xB2\\uC774 \\uBCFC\\uB85D\\uD568\\uC744 \\uBCF4\\uC774\\uC138\\uC694.\",solution:\"f''(x) = 2 > 0 (\\uD56D\\uC0C1 \\uC591\\uC218), \\uB530\\uB77C\\uC11C \\uBCFC\\uB85D\\uD569\\uB2C8\\uB2E4. \\uB610\\uB294: f(\\u03B8a + (1-\\u03B8)b) \\u2264 \\u03B8f(a) + (1-\\u03B8)f(b)\\uB97C \\uC9C1\\uC811 \\uD655\\uC778.\"}],applications:[{field:\"\\uAE30\\uACC4\\uD559\\uC2B5\",description:\"\\uB85C\\uC9C0\\uC2A4\\uD2F1 \\uD68C\\uADC0, SVM\"},{field:\"\\uC2E0\\uD638 \\uCC98\\uB9AC\",description:\"\\uD544\\uD130 \\uC124\\uACC4\"},{field:\"\\uC81C\\uC5B4 \\uC774\\uB860\",description:\"LQR \\uC81C\\uC5B4\"}]},en:{definition:\"Convex optimization minimizes a convex function over a convex set. Local minima are global minima, making it efficiently solvable.\",formulas:[{latex:\"f(\\\\theta x + (1-\\\\theta)y) \\\\leq \\\\theta f(x) + (1-\\\\theta)f(y)\",description:\"Definition of convex function\"},{latex:\"\\\\nabla^2 f(x) \\\\succeq 0\",description:\"Second-order convexity condition (Hessian PSD)\"}],examples:[{problem:\"Show f(x) = x\\xB2 is convex.\",solution:\"f''(x) = 2 > 0 (always positive), so convex. Or verify: f(\\u03B8a + (1-\\u03B8)b) \\u2264 \\u03B8f(a) + (1-\\u03B8)f(b).\"}],applications:[{field:\"Machine Learning\",description:\"Logistic regression, SVM\"},{field:\"Signal Processing\",description:\"Filter design\"},{field:\"Control Theory\",description:\"LQR control\"}]}},relations:{prerequisites:[\"optimization-basics\",\"linear-algebra\"],nextTopics:[\"interior-point-methods\"],related:[\"linear-programming\"]},tags:[\"\\uBCFC\\uB85D\",\"\\uCD5C\\uC801\\uD654\",\"convex\",\"optimization\"]}];export{optimizationConcepts};\n","warnings":[],"map":{"version":3,"mappings":"AAKO,MAAM,qBAAsC,CACjD,CACE,GAAI,sBACJ,KAAM,CACJ,GAAI,kCACJ,GAAI,qBACN,EACA,MAAO,eACP,SAAU,cACV,WAAY,EACZ,QAAS,CACP,GAAI,CACF,WACE,kPACF,SAAU,CACR,CACE,MAAO,yEACP,YAAa,0DACf,EACA,CACE,MAAO,qBACP,YAAa,sEACf,CACF,EACA,SAAU,CACR,CACE,QAAS,iFACT,SACE,iHACJ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,2BAAQ,YAAa,6CAAW,EACzC,CAAE,MAAO,qBAAO,YAAa,iCAAS,EACtC,CAAE,MAAO,eAAM,YAAa,iCAAS,CACvC,CACF,EACA,GAAI,CACF,WACE,mHACF,SAAU,CACR,CACE,MAAO,yEACP,YAAa,8BACf,EACA,CACE,MAAO,qBACP,YAAa,oDACf,CACF,EACA,SAAU,CACR,CACE,QAAS,6CACT,SACE,kFACJ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,mBAAoB,YAAa,4BAA6B,EACvE,CAAE,MAAO,YAAa,YAAa,sBAAuB,EAC1D,CAAE,MAAO,cAAe,YAAa,qBAAsB,CAC7D,CACF,CACF,EACA,UAAW,CACT,cAAe,CAAC,aAAc,UAAU,EACxC,WAAY,CAAC,mBAAoB,sBAAsB,EACvD,QAAS,CAAC,UAAU,CACtB,EACA,KAAM,CAAC,qBAAO,qBAAO,eAAgB,SAAS,CAChD,EACA,CACE,GAAI,mBACJ,KAAM,CACJ,GAAI,kCACJ,GAAI,kBACN,EACA,MAAO,eACP,SAAU,aACV,WAAY,EACZ,QAAS,CACP,GAAI,CACF,WACE,iTACF,SAAU,CACR,CACE,MAAO,yCACP,YAAa,uEACf,EACA,CACE,MAAO,UACP,YAAa,gCACf,CACF,EACA,SAAU,CACR,CACE,QAAS,2HACT,SAAU,2HACZ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,qBAAO,YAAa,iCAAS,EACtC,CAAE,MAAO,2BAAQ,YAAa,0DAAc,EAC5C,CAAE,MAAO,kCAAU,YAAa,2BAAQ,CAC1C,CACF,EACA,GAAI,CACF,WACE,sIACF,SAAU,CACR,CACE,MAAO,yCACP,YAAa,8BACf,EACA,CACE,MAAO,UACP,YAAa,2BACf,CACF,EACA,SAAU,CACR,CACE,QAAS,yEACT,SAAU,yEACZ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,gBAAiB,YAAa,yBAA0B,EACjE,CAAE,MAAO,mBAAoB,YAAa,8BAA+B,EACzE,CAAE,MAAO,eAAgB,YAAa,qBAAsB,CAC9D,CACF,CACF,EACA,UAAW,CACT,cAAe,CAAC,WAAY,YAAY,EACxC,WAAY,CAAC,gBAAiB,gBAAgB,EAC9C,QAAS,CAAC,iBAAiB,CAC7B,EACA,KAAM,CAAC,2BAAQ,qBAAO,mBAAoB,cAAc,CAC1D,EACA,CACE,GAAI,uBACJ,KAAM,CACJ,GAAI,8CACJ,GAAI,sBACN,EACA,MAAO,eACP,SAAU,cACV,WAAY,EACZ,QAAS,CACP,GAAI,CACF,WACE,qTACF,SAAU,CACR,CACE,MAAO,mDACP,YAAa,gCACf,EACA,CACE,MAAO,iCACP,YAAa,mDACf,CACF,EACA,SAAU,CACR,CACE,QAAS,4FACT,SACE,gLACJ,CACF,EACA,QAAS,CACP,aAAc,0DACd,KAAM,aACN,WAAY,mJACd,EACA,aAAc,CACZ,CAAE,MAAO,qBAAO,YAAa,kEAAiB,EAC9C,CAAE,MAAO,qBAAO,YAAa,8CAAY,EACzC,CAAE,MAAO,2BAAQ,YAAa,8BAAW,CAC3C,CACF,EACA,GAAI,CACF,WACE,gJACF,SAAU,CACR,CACE,MAAO,mDACP,YAAa,YACf,EACA,CACE,MAAO,iCACP,YAAa,sBACf,CACF,EACA,SAAU,CACR,CACE,QAAS,qCACT,SACE,+IACJ,CACF,EACA,QAAS,CACP,aAAc,wBACd,KAAM,OACN,WAAY,kEACd,EACA,aAAc,CACZ,CAAE,MAAO,YAAa,YAAa,mCAAoC,EACvE,CAAE,MAAO,UAAW,YAAa,wBAAyB,EAC1D,CAAE,MAAO,mBAAoB,YAAa,kBAAmB,CAC/D,CACF,CACF,EACA,UAAW,CACT,cAAe,CAAC,WAAY,qBAAqB,EACjD,WAAY,CAAC,iBAAkB,qBAAqB,EACpD,QAAS,CAAC,wBAAwB,CACpC,EACA,KAAM,CAAC,2BAAQ,eAAM,WAAY,YAAY,CAC/C,EACA,CACE,GAAI,qBACJ,KAAM,CACJ,GAAI,kCACJ,GAAI,oBACN,EACA,MAAO,eACP,SAAU,SACV,WAAY,EACZ,QAAS,CACP,GAAI,CACF,WACE,iVACF,SAAU,CACR,CACE,MAAO,+DACP,YAAa,2DACf,CACF,EACA,SAAU,CACR,CACE,QAAS,4FACT,SAAU,6IACZ,CACF,EACA,QAAS,CACP,aAAc,kCACd,KAAM,aACN,WACE,sNACJ,EACA,aAAc,CACZ,CAAE,MAAO,4BAAS,YAAa,qDAAc,EAC7C,CAAE,MAAO,eAAM,YAAa,iCAAS,EACrC,CAAE,MAAO,eAAM,YAAa,mDAAY,CAC1C,CACF,EACA,GAAI,CACF,WACE,kIACF,SAAU,CACR,CACE,MAAO,+DACP,YAAa,8BACf,CACF,EACA,SAAU,CACR,CACE,QAAS,yEACT,SACE,kGACJ,CACF,EACA,QAAS,CACP,aAAc,iBACd,KAAM,OACN,WACE,+EACJ,EACA,aAAc,CACZ,CAAE,MAAO,sBAAuB,YAAa,iCAAkC,EAC/E,CAAE,MAAO,YAAa,YAAa,6BAA8B,EACjE,CAAE,MAAO,UAAW,YAAa,wBAAyB,CAC5D,CACF,CACF,EACA,UAAW,CACT,cAAe,CAAC,iBAAkB,cAAc,EAChD,WAAY,CAAC,sBAAuB,SAAS,EAC7C,QAAS,CAAC,mBAAmB,CAC/B,EACA,KAAM,CAAC,2BAAQ,2BAAQ,qBAAsB,IAAI,CACnD,EACA,CACE,GAAI,sBACJ,KAAM,CACJ,GAAI,kCACJ,GAAI,qBACN,EACA,MAAO,eACP,SAAU,SACV,WAAY,EACZ,QAAS,CACP,GAAI,CACF,WACE,6UACF,SAAU,CACR,CACE,MAAO,mEACP,YAAa,8CACf,EACA,CACE,MAAO,4BACP,YAAa,wGACf,CACF,EACA,SAAU,CACR,CACE,QAAS,wEACT,SACE,2MACJ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,2BAAQ,YAAa,4CAAe,EAC7C,CAAE,MAAO,4BAAS,YAAa,2BAAQ,EACvC,CAAE,MAAO,4BAAS,YAAa,kBAAS,CAC1C,CACF,EACA,GAAI,CACF,WACE,qIACF,SAAU,CACR,CACE,MAAO,mEACP,YAAa,+BACf,EACA,CACE,MAAO,4BACP,YAAa,gDACf,CACF,EACA,SAAU,CACR,CACE,QAAS,+BACT,SACE,sHACJ,CACF,EACA,aAAc,CACZ,CAAE,MAAO,mBAAoB,YAAa,0BAA2B,EACrE,CAAE,MAAO,oBAAqB,YAAa,eAAgB,EAC3D,CAAE,MAAO,iBAAkB,YAAa,aAAc,CACxD,CACF,CACF,EACA,UAAW,CACT,cAAe,CAAC,sBAAuB,gBAAgB,EACvD,WAAY,CAAC,wBAAwB,EACrC,QAAS,CAAC,oBAAoB,CAChC,EACA,KAAM,CAAC,eAAM,qBAAO,SAAU,cAAc,CAC9C,CACF","names":[],"ignoreList":[],"sources":["/home/user/public-monorepo/apps/roots/app/data/concepts/optimization.ts"],"sourcesContent":[null]}}