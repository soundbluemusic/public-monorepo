/**
 * ì²­í¬ ê¸°ë°˜ SSG ë¹Œë“œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
 *
 * 100ë§Œ+ í˜ì´ì§€ ê·œëª¨ì˜ SSG ë¹Œë“œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.
 * ê° ì²­í¬ëŠ” ë…ë¦½ì ì¸ ë¹Œë“œ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰ë˜ì–´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•©ë‹ˆë‹¤.
 *
 * @example
 * ```bash
 * # ê¸°ë³¸ ì‹¤í–‰ (50K ì²­í¬)
 * pnpm build:chunked
 *
 * # ì»¤ìŠ¤í…€ ì²­í¬ í¬ê¸°
 * CHUNK_SIZE=100000 pnpm build:chunked
 *
 * # íŠ¹ì • ì²­í¬ë§Œ ë¹Œë“œ
 * CHUNK_INDEX=0 pnpm build:chunked
 * ```
 */

import { execSync } from 'node:child_process';
import { cpSync, existsSync, mkdirSync, rmSync } from 'node:fs';
import { dirname, join } from 'node:path';
import { fileURLToPath } from 'node:url';

const __dirname = dirname(fileURLToPath(import.meta.url));
const projectRoot = join(__dirname, '..');

/** ê¸°ë³¸ ì²­í¬ í¬ê¸° */
const DEFAULT_CHUNK_SIZE = 50000;

/** ë©”ëª¨ë¦¬ ì œí•œ (MB) */
const NODE_MEMORY_LIMIT = 8192;

interface ChunkBuildResult {
  chunkIndex: number;
  success: boolean;
  duration: number;
  routeCount: number;
  error?: string;
}

/**
 * ì²­í¬ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
 */
async function getChunkMetadata(chunkSize: number): Promise<{
  totalEntries: number;
  totalChunks: number;
  chunkSize: number;
  routesPerChunk: number;
}> {
  const { getChunkMetadata } = await import('../app/data/route-chunks.js');
  return getChunkMetadata(chunkSize);
}

/**
 * ë‹¨ì¼ ì²­í¬ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.
 */
function buildChunk(chunkIndex: number, chunkSize: number): ChunkBuildResult {
  const startTime = Date.now();

  console.log(`\n${'='.repeat(60)}`);
  console.log(`ğŸ”¨ Building chunk ${chunkIndex}...`);
  console.log('='.repeat(60));

  try {
    execSync(
      `BUILD_TARGET=chunked CHUNK_INDEX=${chunkIndex} CHUNK_SIZE=${chunkSize} react-router build`,
      {
        cwd: projectRoot,
        stdio: 'inherit',
        env: {
          ...process.env,
          NODE_OPTIONS: `--max-old-space-size=${NODE_MEMORY_LIMIT}`,
        },
      },
    );

    const duration = Date.now() - startTime;

    return {
      chunkIndex,
      success: true,
      duration,
      routeCount: chunkSize * 2, // í•œì˜ ê°ê°
    };
  } catch (error) {
    const duration = Date.now() - startTime;

    return {
      chunkIndex,
      success: false,
      duration,
      routeCount: 0,
      error: error instanceof Error ? error.message : 'Unknown error',
    };
  }
}

/**
 * ëª¨ë“  ì²­í¬ì˜ ë¹Œë“œ ê²°ê³¼ë¬¼ì„ ë³‘í•©í•©ë‹ˆë‹¤.
 */
function mergeChunks(totalChunks: number): void {
  console.log(`\n${'='.repeat(60)}`);
  console.log('ğŸ“¦ Merging chunk outputs...');
  console.log('='.repeat(60));

  const finalOutputDir = join(projectRoot, 'build', 'client');
  const chunksDir = join(projectRoot, 'build', 'chunks');

  // ì²­í¬ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
  if (!existsSync(chunksDir)) {
    mkdirSync(chunksDir, { recursive: true });
  }

  // ê° ì²­í¬ì˜ entry í´ë”ë¥¼ ë³‘í•©
  for (let i = 0; i < totalChunks; i++) {
    const chunkEntryDir = join(chunksDir, `chunk-${i}`, 'entry');
    if (existsSync(chunkEntryDir)) {
      const targetDir = join(finalOutputDir, 'entry');
      if (!existsSync(targetDir)) {
        mkdirSync(targetDir, { recursive: true });
      }
      cpSync(chunkEntryDir, targetDir, { recursive: true });
      console.log(`   âœ“ Merged chunk ${i} entries`);
    }
  }

  console.log('âœ… Merge complete!');
}

/**
 * ë¹Œë“œ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
 */
function printSummary(results: ChunkBuildResult[], totalDuration: number): void {
  console.log(`\n${'='.repeat(60)}`);
  console.log('ğŸ“Š Chunked Build Summary');
  console.log('='.repeat(60));

  let totalRoutes = 0;

  for (const result of results) {
    const status = result.success ? 'âœ…' : 'âŒ';
    const time = `${(result.duration / 1000).toFixed(1)}s`;
    console.log(`   ${status} Chunk ${result.chunkIndex}: ${result.routeCount} routes (${time})`);
    totalRoutes += result.routeCount;
  }

  console.log('-'.repeat(60));
  console.log(`   Total routes: ${totalRoutes}`);
  console.log(`   Total time: ${(totalDuration / 1000).toFixed(1)}s`);

  const failed = results.filter((r) => !r.success);
  if (failed.length > 0) {
    console.log(`\nâŒ ${failed.length} chunk(s) failed`);
    process.exit(1);
  } else {
    console.log('\nâœ… All chunks built successfully!');
  }
}

async function main(): Promise<void> {
  const startTime = Date.now();
  const chunkSize = parseInt(process.env.CHUNK_SIZE || String(DEFAULT_CHUNK_SIZE), 10);
  const specificChunk = process.env.CHUNK_INDEX ? parseInt(process.env.CHUNK_INDEX, 10) : null;

  console.log('ğŸš€ Starting chunked SSG build...');
  console.log(`   Chunk size: ${chunkSize}`);
  console.log(`   Memory limit: ${NODE_MEMORY_LIMIT}MB`);

  // ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
  const metadata = await getChunkMetadata(chunkSize);

  console.log(`   Total entries: ${metadata.totalEntries}`);
  console.log(`   Total chunks: ${metadata.totalChunks}`);

  const results: ChunkBuildResult[] = [];

  if (specificChunk !== null) {
    // íŠ¹ì • ì²­í¬ë§Œ ë¹Œë“œ
    console.log(`\nğŸ“Œ Building only chunk ${specificChunk}`);
    const result = buildChunk(specificChunk, chunkSize);
    results.push(result);
  } else {
    // ëª¨ë“  ì²­í¬ ìˆœì°¨ ë¹Œë“œ
    for (let i = 0; i < metadata.totalChunks; i++) {
      const result = buildChunk(i, chunkSize);
      results.push(result);

      // ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
      if (!result.success) {
        console.error(`\nâŒ Chunk ${i} failed, stopping build`);
        break;
      }
    }

    // ë³‘í•© (ëª¨ë“  ì²­í¬ ì„±ê³µ ì‹œ)
    const allSuccess = results.every((r) => r.success);
    if (allSuccess && metadata.totalChunks > 1) {
      mergeChunks(metadata.totalChunks);
    }
  }

  // ìš”ì•½ ì¶œë ¥
  const totalDuration = Date.now() - startTime;
  printSummary(results, totalDuration);
}

main().catch((err) => {
  console.error('Chunked build failed:', err);
  process.exit(1);
});
